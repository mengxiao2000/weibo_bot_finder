import requests
import pandas as pd
import numpy as np
from tqdm import tqdm
import os
import re
import streamlit as st

class RepostSpider():
    # åˆå§‹åŒ–
    def __init__(self, mid, cookie, print_progres=True, root_path = 'root_weibo.csv', repost_dir='./reposts/' ):
        self.mid = mid
        self.cookie = cookie
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36",
            "cookie":self.cookie
        }
        
        self.print_progress = print_progres # æ˜¯å¦æ‰“å°è¿‡ç¨‹
        
        self.max_page = 1000
        
        self.user_info = pd.DataFrame() # ç”¨æˆ·ä¿¡æ¯
        self.weibo_info = pd.DataFrame() # å¾®åšä¿¡æ¯
        self.repost_df = pd.DataFrame() # è½¬å‘æ•°æ®
        
        self.path = root_path # æ ¹å¾®åšä¿¡æ¯
        self.repost_dir = repost_dir # è½¬å‘å¾®åšæ–‡ä»¶å¤¹
        
    # è·å–é•¿æ¨æ–‡å†…å®¹
    def get_long_weibo(self, mid):
        try:
            long_text = requests.get(f'https://m.weibo.cn/statuses/extend?id={mid}').json()['data']['longTextContent']
            return long_text
        except Exception as e:
            return np.NAN
    
    # è·å–å¾®åšä¿¡æ¯
    def get_weibo_info(self):
        res = requests.get(f'https://m.weibo.cn/statuses/show?id={self.mid}').json()
        if res['ok'] == 1:
            # å¾®åšå†…å®¹ä¿¡æ¯
            mblogid = self.mid
            created_at = res['data']['created_at']
            mid = res['data']['mid']
            text = res['data']['text']
            reposts_count = res['data']['reposts_count']
            comments_count = res['data']['comments_count']
            attitudes_count = res['data']['attitudes_count']
            islongtext = res['data']['isLongText']
            pic_num = res['data']['pic_num']
            
            # ç”¨æˆ·ä¿¡æ¯
            uid = res['data']['user']['id']
            screen_name = res['data']['user']['screen_name']
            gender = res['data']['user']['gender']

            verified_type = res['data']['user']['verified_type']
            verified = res['data']['user']['verified']
            #verified_reason = res['data']['user']['verified_reason']

            follow_count = res['data']['user']['follow_count']
            followers_count = res['data']['user']['followers_count']
            
            if islongtext:
                long_text = self.get_long_weibo(self.mid)
                if pd.notna(long_text):
                    text = long_text

            self.weibo_info = pd.DataFrame([[mblogid, created_at, mid, text, reposts_count, comments_count, attitudes_count, 
                           pic_num, uid, screen_name, gender, verified,  verified_type,
                          follow_count, followers_count]], columns=
                        ["mblogid","created_at", "mid", "text", "reposts_count", "comments_count", "attitudes_count", 
                           "pic_num", "uid", "screen_name", "gender", "verified", "verified_type",
                          "follow_count", "followers_count"])
            
            if self.print_progress:
                print(f'æŠ“å–æ ¹å¾®åšä¿¡æ¯å®Œæˆã€‚')
                    
            return 1
        
        else:
            
            if self.print_progress:
                print(f'æŠ“å–æ ¹å¾®åšä¿¡æ¯å¤±è´¥ã€‚')
                    
            return 0
    
    # è·å–å•é¡µå¾®åš
    def get_one_page(self, page):
        url = f"https://weibo.com/ajax/statuses/repostTimeline?id={self.mid}&page={page}&moduleID=feed&count=20"
        res = requests.get(url, headers=self.headers).json()
        max_page = res['max_page']
        if page == 0: # è·å–é¡µæ•°
            self.max_page = max_page
            return -1 
        
        if res['ok'] == 1:
            df = pd.DataFrame(res['data'])
            df['uid'] = df['user'].apply(lambda x: x['id'])
            df['username'] = df['user'].apply(lambda x: x['screen_name'])
            df = df[['created_at','mid', 'mblogid', 'uid','username','text_raw','reposts_count','comments_count','attitudes_count']]
            self.repost_df = pd.concat([self.repost_df, df], axis=0)

            return 1 # è¡¨ç¤ºçˆ¬å–æˆåŠŸ

        else:
            return 0 # è¡¨ç¤ºçˆ¬å–å¤±è´¥


    # è·å–å…¨éƒ¨è½¬å‘
    def get_all_page(self):
        page = 1
        error = 0
        # è·å–é¡µæ•°
        self.get_one_page(0)
        # å¼€å§‹æŠ“å–
        crawl_info = st.empty()
        crawl_info.write("Start ï¼ ğŸˆ")
        crawl_bar = st.progress(0)

        for page in np.arange(1,self.max_page+1,1):
            
            crawl_bar.progress(page/self.max_page) # è¿›åº¦æ¡
            if error > 10:
                break
            try:
                flag = self.get_one_page(page)

                if flag == 2:
                    break

                if page > 300:
                    break
                    
                if self.print_progress:
                    crawl_info.write(f'æŠ“å–ç¬¬{page}é¡µ/{self.max_page}é¡µï¼Œå½“å‰å…±æŠ“å–åˆ°{len(self.repost_df)}æ¡ã€‚')

            except Exception as e:
                if self.print_progress:
                    crawl_info.write(f'æŠ“å–ç¬¬{page}é¡µ:å‘ç”Ÿå¼‚å¸¸:{e}')
                
                error += 1
                continue
            
                
 
    # æ„é€ è½¬å‘ç»“æ„ up_mid å’Œ root_mid
    def construct_repost_structure(self):
        self.repost_df['up_mid'] = np.NAN # ä¸Šçº§å¾®åš
        self.repost_df['root_mid'] = self.mid # æ ¹å¾®åš
        self.repost_df = self.repost_df.drop_duplicates('mid')
        self.repost_df = self.repost_df.reset_index()
        
        crawl_info = st.empty()
        crawl_info.write("å¼€å§‹æ„é€ è½¬å‘ç½‘ç»œï¼ ")
        crawl_bar = st.progress(0)


        for idx in tqdm(range(len(self.repost_df))):
            crawl_bar.progress((idx+1)/len(self.repost_df)) # è¿›åº¦æ¡
            
            line = self.repost_df.loc[idx, :]
            usernames = re.findall('//@(.*?):',line['text_raw'])
            
            if len(usernames) > 0:
                for up_username in usernames:
                    #print(up_username)
                    up_line = self.repost_df.query('username == @up_username')
                    #print(up_line)
                    if len(up_line) == 1:
                        up_mid =  up_line['mblogid'].values[0]
                        #print(up_mid)
                        self.repost_df.loc[idx, 'up_mid'] = up_mid
                        break
                    elif len(up_line) > 1:
                        #print(up_line)
                        up_mid =  up_line['mblogid'].values[0] # é»˜è®¤é€‰ç¬¬ä¸€ä¸ª
                        self.repost_df.loc[idx, 'up_mid'] = up_mid
                        break
                    else:
                        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä¸Šçº§ç”¨æˆ·
                        # æ‰€æœ‰ä¸Šçº§éƒ½æ²¡æ‰¾åˆ°ï¼Œè¿æ¥åˆ°æ ¹ç”¨æˆ·
                        if  up_username == usernames[-1]:
                            self.repost_df.loc[idx, 'up_mid'] = self.mid
                            break
                        # ç»§ç»­å¯»æ‰¾ä¸Šä¸Šçº§ç”¨æˆ·
                        else:
                            pass
            else:
                self.repost_df.loc[idx, 'up_mid'] = self.mid
    
        crawl_info.write("æ„é€ è½¬å‘ç½‘ç»œå®ŒæˆğŸ‰ ")
        
    # ä¿å­˜åˆ°csv
    def save_repost(self):
        # å­˜å‚¨è½¬å‘
        if not os.path.exists(self.repost_dir):
            os.mkdir(self.repost_dir)
        else:
            pass
        self.repost_df.to_csv(self.repost_dir+str(self.mid)+'.csv',index=None)
        if self.print_progress:
                    print(f'å­˜å‚¨è½¬å‘å¾®åšå®Œæˆã€‚')
    
    def save_weibo_info(self):
        # å­˜å‚¨å¾®åšä¿¡æ¯
        if not os.path.exists(self.path):
            self.weibo_info.to_csv(self.path,index=None)
        else:
            self.weibo_info.to_csv(self.path,index=None, mode='a+', header=None)
        
        if self.print_progress:
                    print(f'å­˜å‚¨å¾®åšä¿¡æ¯å®Œæˆã€‚')
    
    # æ‰§è¡Œ
    def run(self):
        # æŠ“å–
        get_info_status = self.get_weibo_info()
        self.get_all_page()
        
        # æ„é€ 
        self.construct_repost_structure()
        
        # å­˜å‚¨
        self.save_repost()
        if get_info_status == 1:
            self.save_weibo_info()

        
        
        
